{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e9d3eeb9-91d1-4913-bce6-27df6c7f6839",
   "metadata": {},
   "source": [
    "# Monthly LAI\n",
    "We have 7-daily MODIS LAI files. For the perceptual model project, it probably makes sense to have something less impacted by day-to-day variability and short-term weather. We'll find the daily files and create monthly-averaged LAI from these."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8299fefe-35de-44ef-a064-e8d9d597fd83",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "sys.path.append(str(Path().absolute().parent))\n",
    "import _functions as pmf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6afe47c9-e5bc-4a4b-b35c-e8cb9711c143",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify where the config file can be found\n",
    "config_file = '../0_config/config.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3f45310b-91c7-4adb-b500-99066712c3ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the required info from the config file\n",
    "raw_path = pmf.read_from_config(config_file,'raw_path')\n",
    "last_n_years = pmf.read_from_config(config_file,'last_n_years')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "148911e2-d056-4df8-9590-1cf36ab22657",
   "metadata": {},
   "source": [
    "### 1. Find LAI files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c07fc768-7f64-4b5b-b06f-d6dc963aa2e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0515ad5d-265b-4e1f-a9a8-3cf5b5f1ef57",
   "metadata": {},
   "outputs": [],
   "source": [
    "src_path = Path(raw_path) / 'lai' / 'raw'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "91101390-942f-40b9-996d-325e2c4838d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "lai_files = sorted( glob.glob(str(src_path / '*.tif')) )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15afad0b-094d-4169-a593-647809dba8c6",
   "metadata": {},
   "source": [
    "### 2. Create the output directory\n",
    "In this attempt we'll base the monthly LAI values on the last 10 years, so we'll hardcode an appropriate folder name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "be171b4e-a547-4860-a1ea-773985ec6bf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "des_path = Path(raw_path) / 'lai' / 'monthly_average_2013_2023'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1dc1d17d-2d66-42bc-b798-b0689534a9f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "des_path.mkdir(exist_ok=True, parents=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee313be7-6ba6-4cd0-aee2-014d687ac765",
   "metadata": {},
   "source": [
    "### 3. Create monthly average files\n",
    "Averaging code adapted from: https://www.hydroshare.org/resource/1361509511e44adfba814f6950c6e742/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a615d042-a49b-4ffb-ad50-46da7c7597cb",
   "metadata": {},
   "source": [
    "#### 3.1 Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "56b8b362-9c69-4ed4-93eb-8c5d05b5bda6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dateutil.relativedelta import relativedelta\n",
    "import numpy as np\n",
    "from osgeo import gdal, osr\n",
    "import os\n",
    "import pandas as pd\n",
    "import scipy.stats as sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1b378359-ec58-4e12-8e6f-aca5f19c4dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_lai_files_by_date(files, last_n_years=[], last_n_months=[], last_n_days=[],\n",
    "                                    years=[], months=[], days=[]):\n",
    "\n",
    "    '''Filters list of LAI file names by last n years/months/days and/or by year/month/day x.\n",
    "       Assumes date is given as 'yyyymmdd_*.tif', as part of the filename.\n",
    "       Use years/months/days (input as list) to subset further.'''\n",
    "\n",
    "    # Check inputs\n",
    "    if (last_n_years and last_n_months) or \\\n",
    "       (last_n_years and last_n_days) or \\\n",
    "       (last_n_months and last_n_days):\n",
    "        print('WARNING: filter_lai_files_by_date(): specify only one of last_n_years, last_n_months, last_n_days')\n",
    "        return\n",
    "\n",
    "    # Create a DatetimeIndex from filenames\n",
    "    dates = []\n",
    "    for file in files:\n",
    "        file_name = os.path.basename(file)\n",
    "        yyyymmdd = file_name[0:8]\n",
    "        dates.append(yyyymmdd)\n",
    "    dti = pd.to_datetime(dates,format='%Y%m%d')\n",
    "\n",
    "    # Find the last entry\n",
    "    last_year  = dti[-1].year\n",
    "    last_month = dti[-1].month\n",
    "    last_day   = dti[-1].day\n",
    "    \n",
    "    # Select the last n entries\n",
    "    if last_n_years:    start_date = dti[-1] - relativedelta(years = last_n_years)\n",
    "    elif last_n_months: start_date = dti[-1] - relativedelta(months = last_n_months)\n",
    "    elif last_n_days:   start_date = dti[-1] - relativedelta(days = last_n_days)\n",
    "    last_n = (dti >= start_date) & (dti <= dti[-1])\n",
    "\n",
    "    # Specify filters to include all if no specific years/months/days were requested\n",
    "    if not years:  years  = list(set(dti.year))  # i.e. filter to include all unique years in dti, \\\n",
    "    if not months: months = list(set(dti.month)) #    else use user input\n",
    "    if not days:   days   = list(set(dti.day))\n",
    "    mask = dti.year.isin(years) & dti.month.isin(months) & dti.day.isin(days)\n",
    "\n",
    "    # Return the filtered list\n",
    "    return [file for file, bool1, bool2 in zip(files,last_n,mask) if bool1 and bool2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0589d551-1422-4963-ad8d-5e18eff76f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_geotif_data_as_array(file, band=1):\n",
    "    ds = gdal.Open(file) # open the file\n",
    "    band = ds.GetRasterBand(band) # get the data band\n",
    "    data = band.ReadAsArray() # convert to numpy array for further manipulation   \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "37c642f2-f31e-4795-805c-269890bf9c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def enforce_data_range(data,min,max,replace_with='limit'):\n",
    "\n",
    "    '''Clamps data at min and max values'''\n",
    "\n",
    "    if replace_with =='limit':\n",
    "        data[data<min] = min\n",
    "        data[data>max] = max\n",
    "    else:\n",
    "        data[data<min] = replace_with\n",
    "        data[data>max] = replace_with\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9d5ae4ec-bf27-4f3d-b983-4a70dcd27b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_geotif_sameDomain(src_file,des_file,des_data):\n",
    "    \n",
    "    # load the source file to get the appropriate attributes\n",
    "    src_ds = gdal.Open(src_file)\n",
    "    \n",
    "    # get the geotransform\n",
    "    des_transform = src_ds.GetGeoTransform()\n",
    "\n",
    "    # Get the scale factor from the source metadata\n",
    "    scale_factor = src_ds.GetRasterBand(1).GetScale()\n",
    "    offset = src_ds.GetRasterBand(1).GetOffset()\n",
    "    \n",
    "    # get the data dimensions\n",
    "    ncols = des_data.shape[1]\n",
    "    nrows = des_data.shape[0]\n",
    "    \n",
    "    # make the file\n",
    "    driver = gdal.GetDriverByName(\"GTiff\")\n",
    "    dst_ds = driver.Create(des_file,ncols,nrows,1,gdal.GDT_Float32, options = [ 'COMPRESS=DEFLATE' ])\n",
    "    dst_ds.GetRasterBand(1).WriteArray( des_data )\n",
    "\n",
    "    # Set the scale factor in the destination band\n",
    "    dst_ds.GetRasterBand(1).SetScale(scale_factor)\n",
    "    dst_ds.GetRasterBand(1).SetOffset(offset)\n",
    "    \n",
    "    # Set the geotransform\n",
    "    dst_ds.SetGeoTransform(des_transform)\n",
    "\n",
    "    # Set the projection\n",
    "    wkt = src_ds.GetProjection()\n",
    "    srs = osr.SpatialReference()\n",
    "    srs.ImportFromWkt(wkt)\n",
    "    dst_ds.SetProjection( srs.ExportToWkt() )\n",
    "    \n",
    "    # close files\n",
    "    src_ds = None\n",
    "    des_ds = None\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e3f40af-e3ea-41ff-aa47-0f338e2d1788",
   "metadata": {},
   "source": [
    "#### 3.2 Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "564cb763-b201-409c-9f34-51e2e61afa90",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdal.UseExceptions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2749d6b3-2519-4791-9334-d43d7a9981e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define valid data range\n",
    "# See docs, Table 4: https://lpdaac.usgs.gov/documents/926/MOD15_User_Guide_V61.pdf\n",
    "modis_min = 0\n",
    "modis_max = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b21158d-3d87-41eb-9ce1-6b49f75d16d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ffea3649-64f9-4a04-a7cb-ca2c3c212c92",
   "metadata": {},
   "source": [
    "#### DEV(?) - I'm reasonably certain it is dev code. but not sure - check later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6b434c38-3dc3-44ca-b0ec-784dc5a69299",
   "metadata": {},
   "outputs": [],
   "source": [
    "month = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "42238243-5bdd-454f-b509-4d1acdefb61c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing month 01\n"
     ]
    }
   ],
   "source": [
    "print(f'Processing month {month:02d}')\n",
    "month_files = filter_lai_files_by_date(lai_files, last_n_years=last_n_years, months=[month])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "02732356-fb15-4da8-9d48-fc6eba288bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "month_files = [file for file in month_files if '20221016' not in file]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a349b036-67eb-4c27-b9d6-f93840827baa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing/Users/wmk934/data/NorthAmerica_geospatial/lai/raw/20140101_MOD_Grid_MOD15A2H_Lai_500m.tif\n",
      "Processing/Users/wmk934/data/NorthAmerica_geospatial/lai/raw/20140109_MOD_Grid_MOD15A2H_Lai_500m.tif\n",
      "Processing/Users/wmk934/data/NorthAmerica_geospatial/lai/raw/20140117_MOD_Grid_MOD15A2H_Lai_500m.tif\n",
      "Processing/Users/wmk934/data/NorthAmerica_geospatial/lai/raw/20140125_MOD_Grid_MOD15A2H_Lai_500m.tif\n",
      "Processing/Users/wmk934/data/NorthAmerica_geospatial/lai/raw/20150101_MOD_Grid_MOD15A2H_Lai_500m.tif\n",
      "Processing/Users/wmk934/data/NorthAmerica_geospatial/lai/raw/20150109_MOD_Grid_MOD15A2H_Lai_500m.tif\n",
      "Processing/Users/wmk934/data/NorthAmerica_geospatial/lai/raw/20150117_MOD_Grid_MOD15A2H_Lai_500m.tif\n",
      "Processing/Users/wmk934/data/NorthAmerica_geospatial/lai/raw/20150125_MOD_Grid_MOD15A2H_Lai_500m.tif\n",
      "Processing/Users/wmk934/data/NorthAmerica_geospatial/lai/raw/20160101_MOD_Grid_MOD15A2H_Lai_500m.tif\n",
      "Processing/Users/wmk934/data/NorthAmerica_geospatial/lai/raw/20160109_MOD_Grid_MOD15A2H_Lai_500m.tif\n",
      "Processing/Users/wmk934/data/NorthAmerica_geospatial/lai/raw/20160117_MOD_Grid_MOD15A2H_Lai_500m.tif\n",
      "Processing/Users/wmk934/data/NorthAmerica_geospatial/lai/raw/20160125_MOD_Grid_MOD15A2H_Lai_500m.tif\n",
      "Processing/Users/wmk934/data/NorthAmerica_geospatial/lai/raw/20170101_MOD_Grid_MOD15A2H_Lai_500m.tif\n",
      "Processing/Users/wmk934/data/NorthAmerica_geospatial/lai/raw/20170109_MOD_Grid_MOD15A2H_Lai_500m.tif\n",
      "Processing/Users/wmk934/data/NorthAmerica_geospatial/lai/raw/20170117_MOD_Grid_MOD15A2H_Lai_500m.tif\n",
      "Processing/Users/wmk934/data/NorthAmerica_geospatial/lai/raw/20170125_MOD_Grid_MOD15A2H_Lai_500m.tif\n",
      "Processing/Users/wmk934/data/NorthAmerica_geospatial/lai/raw/20180101_MOD_Grid_MOD15A2H_Lai_500m.tif\n",
      "Processing/Users/wmk934/data/NorthAmerica_geospatial/lai/raw/20180109_MOD_Grid_MOD15A2H_Lai_500m.tif\n",
      "Processing/Users/wmk934/data/NorthAmerica_geospatial/lai/raw/20180117_MOD_Grid_MOD15A2H_Lai_500m.tif\n",
      "Processing/Users/wmk934/data/NorthAmerica_geospatial/lai/raw/20180125_MOD_Grid_MOD15A2H_Lai_500m.tif\n",
      "Processing/Users/wmk934/data/NorthAmerica_geospatial/lai/raw/20190101_MOD_Grid_MOD15A2H_Lai_500m.tif\n",
      "Processing/Users/wmk934/data/NorthAmerica_geospatial/lai/raw/20190109_MOD_Grid_MOD15A2H_Lai_500m.tif\n",
      "Processing/Users/wmk934/data/NorthAmerica_geospatial/lai/raw/20190117_MOD_Grid_MOD15A2H_Lai_500m.tif\n",
      "Processing/Users/wmk934/data/NorthAmerica_geospatial/lai/raw/20190125_MOD_Grid_MOD15A2H_Lai_500m.tif\n",
      "Processing/Users/wmk934/data/NorthAmerica_geospatial/lai/raw/20200101_MOD_Grid_MOD15A2H_Lai_500m.tif\n",
      "Processing/Users/wmk934/data/NorthAmerica_geospatial/lai/raw/20200109_MOD_Grid_MOD15A2H_Lai_500m.tif\n",
      "Processing/Users/wmk934/data/NorthAmerica_geospatial/lai/raw/20200117_MOD_Grid_MOD15A2H_Lai_500m.tif\n",
      "Processing/Users/wmk934/data/NorthAmerica_geospatial/lai/raw/20200125_MOD_Grid_MOD15A2H_Lai_500m.tif\n",
      "Processing/Users/wmk934/data/NorthAmerica_geospatial/lai/raw/20210101_MOD_Grid_MOD15A2H_Lai_500m.tif\n",
      "Processing/Users/wmk934/data/NorthAmerica_geospatial/lai/raw/20210109_MOD_Grid_MOD15A2H_Lai_500m.tif\n",
      "Processing/Users/wmk934/data/NorthAmerica_geospatial/lai/raw/20210117_MOD_Grid_MOD15A2H_Lai_500m.tif\n",
      "Processing/Users/wmk934/data/NorthAmerica_geospatial/lai/raw/20210125_MOD_Grid_MOD15A2H_Lai_500m.tif\n",
      "Processing/Users/wmk934/data/NorthAmerica_geospatial/lai/raw/20220101_MOD_Grid_MOD15A2H_Lai_500m.tif\n",
      "Processing/Users/wmk934/data/NorthAmerica_geospatial/lai/raw/20220109_MOD_Grid_MOD15A2H_Lai_500m.tif\n",
      "Processing/Users/wmk934/data/NorthAmerica_geospatial/lai/raw/20220117_MOD_Grid_MOD15A2H_Lai_500m.tif\n",
      "Processing/Users/wmk934/data/NorthAmerica_geospatial/lai/raw/20220125_MOD_Grid_MOD15A2H_Lai_500m.tif\n",
      "Processing/Users/wmk934/data/NorthAmerica_geospatial/lai/raw/20230101_MOD_Grid_MOD15A2H_Lai_500m.tif\n",
      "Processing/Users/wmk934/data/NorthAmerica_geospatial/lai/raw/20230109_MOD_Grid_MOD15A2H_Lai_500m.tif\n",
      "Processing/Users/wmk934/data/NorthAmerica_geospatial/lai/raw/20230117_MOD_Grid_MOD15A2H_Lai_500m.tif\n",
      "Processing/Users/wmk934/data/NorthAmerica_geospatial/lai/raw/20230125_MOD_Grid_MOD15A2H_Lai_500m.tif\n"
     ]
    }
   ],
   "source": [
    "data = []\n",
    "for file in month_files:\n",
    "    print(f'Processing{file}')\n",
    "    data_tmp = get_geotif_data_as_array(file)\n",
    "    #data_tmp = enforce_data_range(data_tmp, modis_min, modis_max, replace_with='limit')\n",
    "    data.append(data_tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "47c89909-7d30-41dc-b7ae-943e3e0af1e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked = np.dstack(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c822d8cc-8549-46b9-a276-76ca7af33461",
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked_msk = np.ma.masked_array(stacked, mask=(stacked>0) & (stacked<249))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "be3b1695-7963-4a4a-92a9-1fcea5dddab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "lai = np.ma.mean(stacked_msk, axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "13e49654-c928-4370-b03d-6844304c27d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_all = np.nanmean(stacked, axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "9f44d7ce-9400-431e-b707-79a46bb2ac33",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_lai[mean_all>=249] = mean_all[mean_all>=249]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07a7e19e-9d6d-41ed-9626-2a4184519b52",
   "metadata": {},
   "source": [
    "#### End DEV (?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "6727d94e-3590-47ca-9866-94ebe5ee5913",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing month 01\n",
      "Processing month 02\n",
      "Processing month 03\n",
      "Processing month 04\n",
      "Processing month 05\n",
      "Processing month 06\n",
      "Processing month 07\n",
      "Processing month 08\n",
      "Processing month 09\n",
      "Processing month 10\n",
      "Processing month 11\n",
      "Processing month 12\n"
     ]
    }
   ],
   "source": [
    "for month in range(1,13):\n",
    "    \n",
    "    # Get the files we have for this month, for the last n years\n",
    "    print(f'Processing month {month:02d}')\n",
    "    month_files = filter_lai_files_by_date(lai_files, last_n_years=last_n_years, months=[month])\n",
    "\n",
    "    # Remove the one file we know is incomplete, 2022-10-16\n",
    "    month_files = [file for file in month_files if '20221016' not in file]\n",
    "    \n",
    "    # Load the data as numpy arrays, stack vertically, and find the mean value (ignoring nan)\n",
    "    data = [get_geotif_data_as_array(file) for file in month_files] # Get data as uint8\n",
    "    stacked = np.dstack(data) # Create a 3D stack\n",
    "    stacked_msk = np.ma.masked_array(stacked, mask=(stacked<modis_min) | (stacked>modis_max)) # Retain valid values only\n",
    "    mean_lai = np.ma.mean(stacked_msk, axis=2)\n",
    "\n",
    "    # Define the no-data locations\n",
    "    #mean_all = np.nanmean(stacked, axis=2) # Any pixel that consistently has no-data in the source files (>= 249) should have a >= 249 mean\n",
    "    #mean_lai[mean_all >= 249] = mean_all[mean_all >= 249] # Place the no-data values in the new monthly-mean-lai file\n",
    "    \n",
    "    # Define output file name and write to disk\n",
    "    src_file = month_files[0] # We use this to copy over domain, projection, data scaling, etc\n",
    "    des_file = str( des_path / f'2013_2023_{month:02d}_MOD_Grid_MOD15A2H_Lai_500m.tif' )\n",
    "    write_geotif_sameDomain(src_file, des_file, mean_lai)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4125f82-56b2-4948-93fc-63de073f781f",
   "metadata": {},
   "source": [
    "### Legacy code\n",
    "The below does work (or st least it should) but it is awfully slow for larger matrices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "257f15ab-8585-4391-9ce3-be4b302e7f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for month in range(1,13):\n",
    "    \n",
    "    # Get the files we have for this month, for the last n years\n",
    "    print(f'Processing month {month:02d}')\n",
    "    month_files = filter_lai_files_by_date(lai_files, last_n_years=last_n_years, months=[month])\n",
    "\n",
    "    # Remove the one file we know is incomplete, 2022-10-16\n",
    "    month_files = [file for file in month_files if '20221016' not in file]\n",
    "    \n",
    "    # Load the data as numpy arrays, stack vertically, and find the mean value (ignoring nan)\n",
    "    # To do so we:\n",
    "    # - get_geotif_data_as_array(file): get the GeoTIFF data in as uint8\n",
    "    # - .astype(np.float32): convert uint8 to float32 so we can insert np.nan values in the same array\n",
    "    # - enforce_data_range([..], modis_min, modis_max, replace_with=np.nan): do the nan replacement\n",
    "    # We need the NaNs because MODIS uses 249-255 as no-data values by default, and keeping those\n",
    "    #    would mess with the averaging\n",
    "    data = [enforce_data_range(get_geotif_data_as_array(file).astype(np.float32),\n",
    "                               modis_min, modis_max, replace_with=np.nan)\n",
    "            for file in month_files]\n",
    "    stacked = np.dstack(data)\n",
    "    mean_lai = np.nanmean(stacked, axis = 2) # This doesn't work well for \n",
    "        \n",
    "    # Define output file name and write to disk\n",
    "    src_file = month_files[0] # We use this to copy over domain, projection, data scaling, etc\n",
    "    des_file = str( des_path / f'2013_2023_{month:02d}_MOD_Grid_MOD15A2H_Lai_500m.tif' )\n",
    "    write_geotif_sameDomain(src_file, des_file, mean_lai)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "perc-model-env",
   "language": "python",
   "name": "perc-model-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
